{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGE_SIZE = 150\n",
    "CAT_FILENAME_PATTERN = 'cat.{}.jpg'\n",
    "DOG_FILENAME_PATTERN = 'dog.{}.jpg'\n",
    "\n",
    "base_dir = os.path.expanduser('~/data/kaggle/dogs-vs-cats')\n",
    "orig_data_dir = os.path.join(base_dir, 'train')\n",
    "\n",
    "small_dir = os.path.join(base_dir, 'small')\n",
    "os.makedirs(small_dir, exist_ok=True)\n",
    "\n",
    "models_dir = os.path.join(small_dir, 'models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(small_dir, 'train')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "valid_dir = os.path.join(small_dir, 'validation')\n",
    "os.makedirs(valid_dir, exist_ok=True)\n",
    "test_dir = os.path.join(small_dir, 'test')\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.makedirs(train_dogs_dir, exist_ok=True)\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.makedirs(train_cats_dir, exist_ok=True)\n",
    "valid_dogs_dir = os.path.join(valid_dir, 'dogs')\n",
    "os.makedirs(valid_dogs_dir, exist_ok=True)\n",
    "valid_cats_dir = os.path.join(valid_dir, 'cats')\n",
    "os.makedirs(valid_cats_dir, exist_ok=True)\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.makedirs(test_dogs_dir, exist_ok=True)\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.makedirs(test_cats_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    hist_dict = history.history\n",
    "    loss_values = hist_dict['loss']\n",
    "    val_loss_values = hist_dict['val_loss']\n",
    "    acc_values = hist_dict['acc']\n",
    "    val_acc_values = hist_dict['val_acc']\n",
    "\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows=2, ncols=1,\n",
    "                                   sharex='all', figsize=(10, 7))\n",
    "    ax0.plot(epochs, loss_values, 'bo')\n",
    "    ax0.plot(epochs, val_loss_values, 'b+')\n",
    "    ax0.set_ylabel('Loss')\n",
    "\n",
    "    ax1.plot(epochs, acc_values, 'bo')\n",
    "    ax1.plot(epochs, val_acc_values, 'b+')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from keras import models\n",
    "from keras import activations\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "print(conv_base.summary())\n",
    "\n",
    "\n",
    "# the last layer of conv_base is\n",
    "# block5_pool (MaxPooling2D)   (None, 4, 4, 512)\n",
    "\n",
    "\n",
    "def extract_features(directory, sample_count, batch_size=20):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count,))\n",
    "    generator = ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    i = 0\n",
    "    for input_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(input_batch)\n",
    "        features[batch_size * i: batch_size * (i + 1)] = features_batch\n",
    "        labels[batch_size * i: batch_size * (i + 1)] = labels_batch\n",
    "        i += 1\n",
    "        print('batch', i, 'out of', np.ceil(float(sample_count) / batch_size))\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def extract_features2(directory, sample_count, batch_size=20):\n",
    "    features = []\n",
    "    labels = []\n",
    "    generator = ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    i = 0\n",
    "    for input_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(input_batch)\n",
    "        features += features_batch\n",
    "        labels += labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return np.concatenate(features, axis=0), \\\n",
    "           np.concatenate(labels, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "batch 1 out of 100.0\n",
      "batch 2 out of 100.0\n",
      "batch 3 out of 100.0\n",
      "batch 4 out of 100.0\n",
      "batch 5 out of 100.0\n",
      "batch 6 out of 100.0\n",
      "batch 7 out of 100.0\n",
      "batch 8 out of 100.0\n",
      "batch 9 out of 100.0\n",
      "batch 10 out of 100.0\n",
      "batch 11 out of 100.0\n",
      "batch 12 out of 100.0\n",
      "batch 13 out of 100.0\n",
      "batch 14 out of 100.0\n",
      "batch 15 out of 100.0\n",
      "batch 16 out of 100.0\n",
      "batch 17 out of 100.0\n",
      "batch 18 out of 100.0\n",
      "batch 19 out of 100.0\n",
      "batch 20 out of 100.0\n",
      "batch 21 out of 100.0\n",
      "batch 22 out of 100.0\n",
      "batch 23 out of 100.0\n",
      "batch 24 out of 100.0\n",
      "batch 25 out of 100.0\n",
      "batch 26 out of 100.0\n",
      "batch 27 out of 100.0\n",
      "batch 28 out of 100.0\n",
      "batch 29 out of 100.0\n",
      "batch 30 out of 100.0\n",
      "batch 31 out of 100.0\n",
      "batch 32 out of 100.0\n",
      "batch 33 out of 100.0\n",
      "batch 34 out of 100.0\n",
      "batch 35 out of 100.0\n",
      "batch 36 out of 100.0\n",
      "batch 37 out of 100.0\n",
      "batch 38 out of 100.0\n",
      "batch 39 out of 100.0\n",
      "batch 40 out of 100.0\n",
      "batch 41 out of 100.0\n",
      "batch 42 out of 100.0\n",
      "batch 43 out of 100.0\n",
      "batch 44 out of 100.0\n",
      "batch 45 out of 100.0\n",
      "batch 46 out of 100.0\n",
      "batch 47 out of 100.0\n",
      "batch 48 out of 100.0\n",
      "batch 49 out of 100.0\n",
      "batch 50 out of 100.0\n",
      "batch 51 out of 100.0\n",
      "batch 52 out of 100.0\n",
      "batch 53 out of 100.0\n",
      "batch 54 out of 100.0\n",
      "batch 55 out of 100.0\n",
      "batch 56 out of 100.0\n",
      "batch 57 out of 100.0\n",
      "batch 58 out of 100.0\n",
      "batch 59 out of 100.0\n",
      "batch 60 out of 100.0\n",
      "batch 61 out of 100.0\n",
      "batch 62 out of 100.0\n",
      "batch 63 out of 100.0\n",
      "batch 64 out of 100.0\n",
      "batch 65 out of 100.0\n",
      "batch 66 out of 100.0\n",
      "batch 67 out of 100.0\n",
      "batch 68 out of 100.0\n",
      "batch 69 out of 100.0\n",
      "batch 70 out of 100.0\n",
      "batch 71 out of 100.0\n",
      "batch 72 out of 100.0\n",
      "batch 73 out of 100.0\n",
      "batch 74 out of 100.0\n",
      "batch 75 out of 100.0\n",
      "batch 76 out of 100.0\n",
      "batch 77 out of 100.0\n",
      "batch 78 out of 100.0\n",
      "batch 79 out of 100.0\n",
      "batch 80 out of 100.0\n",
      "batch 81 out of 100.0\n",
      "batch 82 out of 100.0\n",
      "batch 83 out of 100.0\n",
      "batch 84 out of 100.0\n",
      "batch 85 out of 100.0\n",
      "batch 86 out of 100.0\n",
      "batch 87 out of 100.0\n",
      "batch 88 out of 100.0\n",
      "batch 89 out of 100.0\n",
      "batch 90 out of 100.0\n",
      "batch 91 out of 100.0\n",
      "batch 92 out of 100.0\n",
      "batch 93 out of 100.0\n",
      "batch 94 out of 100.0\n",
      "batch 95 out of 100.0\n",
      "batch 96 out of 100.0\n",
      "batch 97 out of 100.0\n",
      "batch 98 out of 100.0\n",
      "batch 99 out of 100.0\n",
      "batch 100 out of 100.0\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "batch 1 out of 50.0\n",
      "batch 2 out of 50.0\n",
      "batch 3 out of 50.0\n",
      "batch 4 out of 50.0\n",
      "batch 5 out of 50.0\n",
      "batch 6 out of 50.0\n",
      "batch 7 out of 50.0\n",
      "batch 8 out of 50.0\n",
      "batch 9 out of 50.0\n",
      "batch 10 out of 50.0\n",
      "batch 11 out of 50.0\n",
      "batch 12 out of 50.0\n",
      "batch 13 out of 50.0\n",
      "batch 14 out of 50.0\n",
      "batch 15 out of 50.0\n",
      "batch 16 out of 50.0\n",
      "batch 17 out of 50.0\n",
      "batch 18 out of 50.0\n",
      "batch 19 out of 50.0\n",
      "batch 20 out of 50.0\n",
      "batch 21 out of 50.0\n",
      "batch 22 out of 50.0\n",
      "batch 23 out of 50.0\n",
      "batch 24 out of 50.0\n",
      "batch 25 out of 50.0\n",
      "batch 26 out of 50.0\n",
      "batch 27 out of 50.0\n",
      "batch 28 out of 50.0\n",
      "batch 29 out of 50.0\n",
      "batch 30 out of 50.0\n",
      "batch 31 out of 50.0\n",
      "batch 32 out of 50.0\n",
      "batch 33 out of 50.0\n",
      "batch 34 out of 50.0\n",
      "batch 35 out of 50.0\n",
      "batch 36 out of 50.0\n",
      "batch 37 out of 50.0\n",
      "batch 38 out of 50.0\n",
      "batch 39 out of 50.0\n",
      "batch 40 out of 50.0\n",
      "batch 41 out of 50.0\n",
      "batch 42 out of 50.0\n",
      "batch 43 out of 50.0\n",
      "batch 44 out of 50.0\n",
      "batch 45 out of 50.0\n",
      "batch 46 out of 50.0\n",
      "batch 47 out of 50.0\n",
      "batch 48 out of 50.0\n",
      "batch 49 out of 50.0\n",
      "batch 50 out of 50.0\n",
      "Found 1000 images belonging to 2 classes.\n",
      "batch 1 out of 50.0\n",
      "batch 2 out of 50.0\n",
      "batch 3 out of 50.0\n",
      "batch 4 out of 50.0\n",
      "batch 5 out of 50.0\n",
      "batch 6 out of 50.0\n",
      "batch 7 out of 50.0\n",
      "batch 8 out of 50.0\n",
      "batch 9 out of 50.0\n",
      "batch 10 out of 50.0\n",
      "batch 11 out of 50.0\n",
      "batch 12 out of 50.0\n",
      "batch 13 out of 50.0\n",
      "batch 14 out of 50.0\n",
      "batch 15 out of 50.0\n",
      "batch 16 out of 50.0\n",
      "batch 17 out of 50.0\n",
      "batch 18 out of 50.0\n",
      "batch 19 out of 50.0\n",
      "batch 20 out of 50.0\n",
      "batch 21 out of 50.0\n",
      "batch 22 out of 50.0\n",
      "batch 23 out of 50.0\n",
      "batch 24 out of 50.0\n",
      "batch 25 out of 50.0\n",
      "batch 26 out of 50.0\n",
      "batch 27 out of 50.0\n",
      "batch 28 out of 50.0\n",
      "batch 29 out of 50.0\n",
      "batch 30 out of 50.0\n",
      "batch 31 out of 50.0\n",
      "batch 32 out of 50.0\n",
      "batch 33 out of 50.0\n",
      "batch 34 out of 50.0\n",
      "batch 35 out of 50.0\n",
      "batch 36 out of 50.0\n",
      "batch 37 out of 50.0\n",
      "batch 38 out of 50.0\n",
      "batch 39 out of 50.0\n",
      "batch 40 out of 50.0\n",
      "batch 41 out of 50.0\n",
      "batch 42 out of 50.0\n",
      "batch 43 out of 50.0\n",
      "batch 44 out of 50.0\n",
      "batch 45 out of 50.0\n",
      "batch 46 out of 50.0\n",
      "batch 47 out of 50.0\n",
      "batch 48 out of 50.0\n",
      "batch 49 out of 50.0\n",
      "batch 50 out of 50.0\n"
     ]
    }
   ],
   "source": [
    "valid_features, valid_labels = extract_features(valid_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train new classifier on extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.7347 - acc: 0.7535 - val_loss: 0.3479 - val_acc: 0.8300\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.3583 - acc: 0.8485 - val_loss: 0.2528 - val_acc: 0.9010\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.3093 - acc: 0.8720 - val_loss: 0.3429 - val_acc: 0.8460\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.2470 - acc: 0.9055 - val_loss: 0.9423 - val_acc: 0.6860\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.2415 - acc: 0.9060 - val_loss: 0.4619 - val_acc: 0.8460\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.1952 - acc: 0.9240 - val_loss: 0.3742 - val_acc: 0.8680\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.1891 - acc: 0.9265 - val_loss: 0.5232 - val_acc: 0.8480\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.1562 - acc: 0.9400 - val_loss: 0.3744 - val_acc: 0.8940\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 4s - loss: 0.1554 - acc: 0.9390 - val_loss: 0.3517 - val_acc: 0.9040\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 4s - loss: 0.1276 - acc: 0.9550 - val_loss: 0.3420 - val_acc: 0.8960\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0915 - acc: 0.9625 - val_loss: 0.4035 - val_acc: 0.8990\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.1030 - acc: 0.9625 - val_loss: 0.3781 - val_acc: 0.8960\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0775 - acc: 0.9670 - val_loss: 0.4171 - val_acc: 0.8990\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0792 - acc: 0.9750 - val_loss: 0.4980 - val_acc: 0.8830\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0780 - acc: 0.9720 - val_loss: 0.4414 - val_acc: 0.8970\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0644 - acc: 0.9795 - val_loss: 0.6247 - val_acc: 0.8910\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0611 - acc: 0.9795 - val_loss: 0.5477 - val_acc: 0.8990\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0568 - acc: 0.9810 - val_loss: 0.5103 - val_acc: 0.9010\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0541 - acc: 0.9810 - val_loss: 0.6860 - val_acc: 0.8890\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0551 - acc: 0.9830 - val_loss: 0.6104 - val_acc: 0.9080\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0402 - acc: 0.9845 - val_loss: 0.5913 - val_acc: 0.9050\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0346 - acc: 0.9890 - val_loss: 0.6918 - val_acc: 0.9000\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0316 - acc: 0.9865 - val_loss: 0.6524 - val_acc: 0.8860\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0360 - acc: 0.9880 - val_loss: 0.8269 - val_acc: 0.8730\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0340 - acc: 0.9885 - val_loss: 0.6749 - val_acc: 0.8980\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0249 - acc: 0.9910 - val_loss: 0.6648 - val_acc: 0.8930\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0269 - acc: 0.9905 - val_loss: 0.7741 - val_acc: 0.8930\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0274 - acc: 0.9890 - val_loss: 0.9776 - val_acc: 0.8810\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 3s - loss: 0.0320 - acc: 0.9910 - val_loss: 0.7207 - val_acc: 0.9060\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 4s - loss: 0.0311 - acc: 0.9925 - val_loss: 0.7400 - val_acc: 0.9050\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Flatten(input_shape=(4, 4, 512)))\n",
    "model.add(Dense(256, activation=relu))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=sigmoid))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(valid_features, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAGfCAYAAAAAp5V2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABk7P8DFnw5wFbe0sYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4232af7780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine new classifier with conv_base from VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = models.Sequential()\n",
    "combined.add(conv_base)\n",
    "combined.add(model)\n",
    "combined.compile(optimizer=optimizers.RMSprop(),\n",
    "                loss=losses.binary_crossentropy,\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.81684434413909912, 0.94999998807907104]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.evaluate_generator(valid_generator, steps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
